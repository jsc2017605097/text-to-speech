import requests
import time
import traceback
import re
import asyncio
import edge_tts
import unicodedata
from pydub import AudioSegment
import os
import sys

# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n ffmpeg khi ƒë√≥ng g√≥i
if getattr(sys, 'frozen', False):
    base_path = sys._MEIPASS
    ffmpeg_path = os.path.join(base_path, "ffmpeg.exe")
else:
    ffmpeg_path = "ffmpeg.exe"
AudioSegment.converter = ffmpeg_path

MODEL = "deepseek/deepseek-r1:free"
API_URL = "https://openrouter.ai/api/v1/chat/completions"


def slugify(text: str) -> str:
    # Chuy·ªÉn Unicode v·ªÅ ASCII, lowercase, thay k√Ω t·ª± kh√¥ng alnum th√†nh d·∫•u '-'
    text = unicodedata.normalize('NFD', text)
    text = text.encode('ascii', 'ignore').decode('utf-8')
    text = text.lower()
    text = re.sub(r'[^a-z0-9]+', '-', text)
    return text.strip('-')


def clean_for_tts(text: str) -> str:
    """
    L√†m s·∫°ch vƒÉn b·∫£n ƒë·ªÉ chuy·ªÉn sang TTS:
    - Gi·ªØ l·∫°i ch·ªØ c√°i (c·∫£ ti·∫øng Vi·ªát), s·ªë v√† d·∫•u c√¢u c∆° b·∫£n
    - Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, d·∫•u ngo·∫∑c, markdown...
    """
    import unicodedata

    # Chu·∫©n h√≥a Unicode ƒë·ªÉ tr√°nh k√Ω t·ª± l·∫°
    text = unicodedata.normalize('NFKC', text)

    # Lo·∫°i b·ªè markdown ** ** ho·∫∑c * *
    text = re.sub(r"\*\*.*?\*\*", "", text)
    text = re.sub(r"\*.*?\*", "", text)

    # X√≥a n·ªôi dung trong ngo·∫∑c tr√≤n ( ), vu√¥ng [ ], nh·ªçn < >, ngo·∫∑c k√©p
    text = re.sub(r"[\(\)\[\]\{\}<>\"‚Äú‚Äù‚Äò‚Äô']", "", text)

    # X√≥a c√°c h∆∞·ªõng d·∫´n nh∆∞ "Camera:..." ho·∫∑c "--- PH·∫¶N X ---"
    text = re.sub(r"Camera.*?\.", "", text)
    text = re.split(r"(?m)^(N·∫øu b·∫°n mu·ªën|---\s*PH·∫¶N\s*\d+\s*---)", text)[0]

    # Ch·ªâ gi·ªØ l·∫°i c√°c k√Ω t·ª± h·ª£p l·ªá cho TTS: ch·ªØ c√°i (c√≥ d·∫•u), s·ªë v√† d·∫•u c√¢u th∆∞·ªùng
    text = re.sub(r"[^a-zA-Z√Ä-·ªπ0-9\s\.,!?:;\-‚Ä¶]", "", text)

    # R√∫t g·ªçn kho·∫£ng tr·∫Øng
    text = re.sub(r"\s+", " ", text).strip()

    return text



async def create_audio_from_text(text: str, output_path: str, voice: str = "vi-VN-HoaiMyNeural"):
    communicate = edge_tts.Communicate(text=text, voice=voice)
    await communicate.save(output_path)


def merge_audio_files(output_file: str, pattern: str, num_parts: int):
    print("\nüîÑ ƒêang g·ªôp c√°c ph·∫ßn √¢m thanh l·∫°i th√†nh 1 file...")
    merged = AudioSegment.empty()
    for i in range(num_parts):
        part_file = pattern.format(i + 1)
        if os.path.exists(part_file):
            audio = AudioSegment.from_file(part_file, format="mp3")
            merged += audio
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y: {part_file}, b·ªè qua.")
    merged.export(output_file, format="mp3")
    print(f"‚úÖ ƒê√£ t·∫°o file g·ªôp: {output_file}")


def run_convert(
    topic: str,
    api_key: str,
    num_parts: int = 12,
    log_func=print,
    voice: str = "vi-VN-HoaiMyNeural"
) -> str:
    log_func(f"üöÄ B·∫Øt ƒë·∫ßu ch·∫°y v·ªõi ch·ªß ƒë·ªÅ: {topic}")
    log_func(f"üîë D√πng API key: {api_key[:6]}***")
    log_func(f"üìÑ S·ªë ph·∫ßn: {num_parts}")

    HEADERS = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    base = slugify(topic)
    output_dir = os.path.join("output", base)
    os.makedirs(output_dir, exist_ok=True)

    output_script = os.path.join(output_dir, f"{base}.txt")
    output_clean = os.path.join(output_dir, f"{base}-clean.txt")

    def call_openrouter(messages):
        try:
            data = {"model": MODEL, "messages": messages}
            res = requests.post(API_URL, headers=HEADERS, json=data)
            if res.status_code != 200:
                log_func(f"‚ùå HTTP {res.status_code} - {res.text}")
                return None
            return res.json()["choices"][0]["message"]["content"]
        except Exception:
            log_func("‚ùå L·ªói khi g·ªçi API:")
            log_func(traceback.format_exc())
            return None

    messages = []
    for i in range(num_parts):
        log_func(f"\nüü° ƒêang l·∫•y ph·∫ßn {i+1}...")
        if i == 0:
            # System message ƒë·ªÉ model ch·ªâ vi·∫øt n·ªôi dung k·ªÉ chuy·ªán
            messages = [
                {
                    "role": "system",
                    "content": (
                        "B·∫°n l√† tr·ª£ l√Ω chuy√™n vi·∫øt k·ªãch b·∫£n k·ªÉ chuy·ªán. "
                        "KH√îNG ƒë∆∞·ª£c th√™m b·∫•t k·ª≥ ph·∫ßn t√≥m t·∫Øt, ph√¢n t√≠ch, g·ª£i √Ω hay meta n√†o."
                    )
                }
            ]
            prompt = (
                f"Vi·∫øt ph·∫ßn m·ªü ƒë·∫ßu c·ªßa c√¢u chuy·ªán c·∫£m ƒë·ªông v·ªõi ch·ªß ƒë·ªÅ: '{topic}'.\n\n"
                "Y√™u c·∫ßu:\n"
                "- Vi·∫øt gi·ªçng vƒÉn t·ª± s·ª±, c·∫£m x√∫c, kho·∫£ng 500 t·ª´.\n"
                "- KH√îNG s·ª≠ d·ª•ng b·∫•t k·ª≥ k√Ω hi·ªáu ƒë·∫∑c bi·ªát, d·∫•u ngo·∫∑c k√©p, d·∫•u ngo·∫∑c ƒë∆°n, ho·∫∑c d·∫•u ngo·∫∑c tr√≤n.\n"
                "- KH√îNG d√πng markdown (*, **, #, v.v.)\n"
                "- Gi·ªØ l·∫°i d·∫•u ch·∫•m, ph·∫©y, ch·∫•m than, ch·∫•m h·ªèi v√† c√°c d·∫•u c√¢u th√¥ng th∆∞·ªùng.\n"
                "- Tr·∫£ v·ªÅ n·ªôi dung thu·∫ßn vƒÉn b·∫£n, s·∫°ch, kh√¥ng ƒë·ªãnh d·∫°ng ho·∫∑c ch√∫ th√≠ch th√™m.\n\n"
                "Ch·ªâ tr·∫£ l·∫°i n·ªôi dung k·ªãch b·∫£n, kh√¥ng th√™m ph·∫ßn meta ho·∫∑c h∆∞·ªõng d·∫´n."
            )

            messages.append({"role": "user", "content": prompt})
        else:
            if i == num_parts - 1:
                cont = (
                    "Vi·∫øt ph·∫ßn k·∫øt c·ªßa c√¢u chuy·ªán, k·∫øt b·∫±ng c·∫£m x√∫c s√¢u l·∫Øng, kho·∫£ng 500 t·ª´.\n\n"
                    "Y√™u c·∫ßu gi·ªëng nh∆∞ ph·∫ßn tr∆∞·ªõc:\n"
                    "- KH√îNG s·ª≠ d·ª•ng d·∫•u ngo·∫∑c, markdown ho·∫∑c k√Ω hi·ªáu ƒë·∫∑c bi·ªát.\n"
                    "- Ch·ªâ tr·∫£ l·∫°i vƒÉn b·∫£n s·∫°ch v·ªõi d·∫•u c√¢u th√¥ng th∆∞·ªùng."
                )

            else:
                cont = (
                    "Vi·∫øt ti·∫øp ph·∫ßn th√¢n c·ªßa c√¢u chuy·ªán (li·ªÅn m·∫°ch, kh√¥ng l·∫∑p l·∫°i), kho·∫£ng 500 t·ª´.\n\n"
                    "Y√™u c·∫ßu gi·ªëng nh∆∞ ph·∫ßn tr∆∞·ªõc:\n"
                    "- KH√îNG s·ª≠ d·ª•ng d·∫•u ngo·∫∑c, markdown ho·∫∑c k√Ω hi·ªáu ƒë·∫∑c bi·ªát.\n"
                    "- Ch·ªâ tr·∫£ l·∫°i vƒÉn b·∫£n s·∫°ch v·ªõi d·∫•u c√¢u th√¥ng th∆∞·ªùng."
                )

            messages.append({"role": "user", "content": cont})

        reply = call_openrouter(messages)
        if not reply or len(reply.strip()) < 50:
            log_func(f"‚ö†Ô∏è Ph·∫ßn {i+1} r·ªóng ho·∫∑c qu√° ng·∫Øn, b·ªè qua.")
            continue
        log_func(f"‚úÖ ƒê√£ nh·∫≠n ph·∫ßn {i+1}. ƒêang x·ª≠ l√Ω...")
        with open(output_script, "a", encoding="utf-8") as f:
            f.write(f"\n--- PH·∫¶N {i+1} ---\n")
            f.write(reply.strip() + "\n")

        cleaned = clean_for_tts(reply)
        with open(output_clean, "a", encoding="utf-8") as f:
            f.write(f"\n--- PH·∫¶N {i+1} ---\n")
            f.write(cleaned + "\n")

        audio_file = os.path.join(output_dir, f"{base}-part-{i+1}.mp3")
        asyncio.run(create_audio_from_text(cleaned, audio_file, voice))
        log_func(f"üéß ƒê√£ t·∫°o file √¢m thanh: {audio_file}")

        messages.append({"role": "assistant", "content": reply})
        time.sleep(10)

    final_audio = os.path.join(output_dir, f"{base}-final.mp3")
    merge_audio_files(
        final_audio,
        os.path.join(output_dir, f"{base}-part-{{}}.mp3"),
        num_parts
    )
    log_func(f"\nüéâ Ho√†n t·∫•t. Audio g·ªôp t·∫°i: {final_audio}")
    return final_audio


if __name__ == "__main__":
    TEST_KEY = "sk-or-v1-your_api_key_here"
    TEST_TOPIC = "T·∫°i Sao Nh·∫≠t B·∫£n G·∫ßn Nh∆∞ Kh√¥ng C√≥ Tr·ªôm C·∫Øp?"
    run_convert(TEST_TOPIC, TEST_KEY)
