import asyncio
import edge_tts
import unicodedata
from pydub import AudioSegment
import os
import sys
import re
import time

# XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n ffmpeg khi Ä‘Ã³ng gÃ³i
if getattr(sys, 'frozen', False):
    base_path = sys._MEIPASS
    ffmpeg_path = os.path.join(base_path, "ffmpeg.exe")
else:
    # Cáº§n Ä‘áº£m báº£o ffmpeg.exe cÃ³ trong PATH hoáº·c cÃ¹ng thÆ° má»¥c vá»›i script
    ffmpeg_path = "ffmpeg.exe"
AudioSegment.converter = ffmpeg_path

def clean_for_tts(text: str) -> str:
    """
    LÃ m sáº¡ch vÄƒn báº£n Ä‘á»ƒ chuyá»ƒn sang TTS:
    - Giá»¯ láº¡i chá»¯ cÃ¡i (cáº£ tiáº¿ng Viá»‡t), sá»‘ vÃ  dáº¥u cÃ¢u cÆ¡ báº£n
    - Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, dáº¥u ngoáº·c, markdown...
    """
    import unicodedata

    # Chuáº©n hÃ³a Unicode Ä‘á»ƒ trÃ¡nh kÃ½ tá»± láº¡
    text = unicodedata.normalize('NFKC', text)

    # Loáº¡i bá» markdown ** ** hoáº·c * *
    text = re.sub(r"\*\*.*?\*\*", "", text)
    text = re.sub(r"\*.*?\*", "", text)

    # XÃ³a ná»™i dung trong ngoáº·c trÃ²n ( ), vuÃ´ng [ ], nhá»n < >, ngoáº·c kÃ©p
    text = re.sub(r"[\(\)\[\]\{\}<>\"""''']", "", text)

    # XÃ³a cÃ¡c hÆ°á»›ng dáº«n nhÆ° "Camera:..." hoáº·c "--- PHáº¦N X ---"
    text = re.sub(r"Camera.*?\.", "", text)
    text = re.sub(r"(?m)^---.*?---", "", text)
    
    # Chá»‰ giá»¯ láº¡i cÃ¡c kÃ½ tá»± há»£p lá»‡ cho TTS: chá»¯ cÃ¡i (cÃ³ dáº¥u), sá»‘, dáº¥u cÃ¢u cÆ¡ báº£n vÃ  khoáº£ng tráº¯ng
    text = re.sub(r"[^a-zA-ZÃ€-á»¹0-9\s\.,!?:;\-â€¦]", "", text)

    # RÃºt gá»n khoáº£ng tráº¯ng
    text = re.sub(r"\s+", " ", text).strip()

    return text

def split_text_by_length(text: str, max_length: int = 5000) -> list:
    """
    Chia vÄƒn báº£n thÃ nh cÃ¡c pháº§n nhá» hÆ¡n dá»±a trÃªn Ä‘á»™ dÃ i kÃ½ tá»±
    Æ¯u tiÃªn cáº¯t táº¡i dáº¥u cÃ¢u Ä‘á»ƒ giá»¯ tÃ­nh tá»± nhiÃªn
    """
    if len(text) <= max_length:
        return [text]
    
    parts = []
    current_pos = 0
    
    while current_pos < len(text):
        # Láº¥y Ä‘oáº¡n text cÃ³ Ä‘á»™ dÃ i tá»‘i Ä‘a
        end_pos = min(current_pos + max_length, len(text))
        
        # Náº¿u chÆ°a háº¿t vÄƒn báº£n, tÃ¬m vá»‹ trÃ­ cáº¯t tá»‘t nháº¥t
        if end_pos < len(text):
            # TÃ¬m dáº¥u cÃ¢u gáº§n nháº¥t trong khoáº£ng 500 kÃ½ tá»± cuá»‘i
            best_cut = end_pos
            for i in range(max(current_pos + max_length - 500, current_pos), end_pos):
                if text[i] in '.!?;':
                    best_cut = i + 1
                    break
            end_pos = best_cut
        
        part = text[current_pos:end_pos].strip()
        if part:
            parts.append(part)
        
        current_pos = end_pos
    
    return parts

def split_text_by_sentences(text: str, max_sentences: int = 50) -> list:
    """
    Chia vÄƒn báº£n thÃ nh cÃ¡c pháº§n dá»±a trÃªn sá»‘ cÃ¢u
    """
    # TÃ¡ch cÃ¢u dá»±a trÃªn dáº¥u cÃ¢u
    sentences = re.split(r'[.!?;]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    if len(sentences) <= max_sentences:
        return [text]
    
    parts = []
    current_part = []
    
    for sentence in sentences:
        current_part.append(sentence)
        
        if len(current_part) >= max_sentences:
            parts.append('. '.join(current_part) + '.')
            current_part = []
    
    # ThÃªm pháº§n cuá»‘i náº¿u cÃ²n
    if current_part:
        parts.append('. '.join(current_part) + '.')
    
    return parts

async def create_audio_from_text(text: str, output_path: str, voice: str = "vi-VN-NamMinhNeural"):
    """Táº¡o file audio tá»« text sá»­ dá»¥ng Edge TTS"""
    try:
        communicate = edge_tts.Communicate(text=text, voice=voice)
        await communicate.save(output_path)
        return True
    except Exception as e:
        print(f"âŒ Lá»—i khi táº¡o audio: {e}")
        return False

def merge_audio_files(output_file: str, audio_files: list):
    """Gá»™p nhiá»u file audio thÃ nh má»™t file duy nháº¥t"""
    print(f"\nğŸ”„ Äang gá»™p {len(audio_files)} file audio...")
    
    merged = AudioSegment.empty()
    successful_files = 0
    
    for audio_file in audio_files:
        if os.path.exists(audio_file):
            try:
                audio = AudioSegment.from_file(audio_file, format="mp3")
                merged += audio
                successful_files += 1
                print(f"âœ… ÄÃ£ thÃªm: {os.path.basename(audio_file)}")
            except Exception as e:
                print(f"âš ï¸ Lá»—i khi Ä‘á»c {audio_file}: {e}")
        else:
            print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y: {audio_file}")
    
    if successful_files > 0:
        merged.export(output_file, format="mp3")
        print(f"âœ… ÄÃ£ táº¡o file gá»™p: {output_file}")
        print(f"ğŸ“Š ÄÃ£ gá»™p {successful_files}/{len(audio_files)} file thÃ nh cÃ´ng")
        return True
    else:
        print("âŒ KhÃ´ng cÃ³ file audio nÃ o Ä‘á»ƒ gá»™p")
        return False

def convert_text_file_to_speech(
    input_file: str,
    output_dir: str = None,
    voice: str = "vi-VN-NamMinhNeural",
    split_method: str = "length",  # "length" hoáº·c "sentences"
    max_length: int = 5000,
    max_sentences: int = 50,
    log_func=print
) -> str:
    """
    Convert file text thÃ nh speech
    
    Args:
        input_file: ÄÆ°á»ng dáº«n file txt Ä‘áº§u vÃ o
        output_dir: ThÆ° má»¥c output (máº·c Ä‘á»‹nh cÃ¹ng thÆ° má»¥c vá»›i input)
        voice: Giá»ng Ä‘á»c Edge TTS
        split_method: PhÆ°Æ¡ng phÃ¡p chia text ("length" hoáº·c "sentences")
        max_length: Äá»™ dÃ i tá»‘i Ä‘a má»—i pháº§n (khi dÃ¹ng method "length")
        max_sentences: Sá»‘ cÃ¢u tá»‘i Ä‘a má»—i pháº§n (khi dÃ¹ng method "sentences")
        log_func: HÃ m Ä‘á»ƒ log
    
    Returns:
        ÄÆ°á»ng dáº«n file audio cuá»‘i cÃ¹ng
    """
    
    if not os.path.exists(input_file):
        log_func(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {input_file}")
        return ""
    
    # XÃ¡c Ä‘á»‹nh thÆ° má»¥c output
    if output_dir is None:
        output_dir = os.path.dirname(input_file)
    os.makedirs(output_dir, exist_ok=True)
    
    # Táº¡o tÃªn file output
    base_name = os.path.splitext(os.path.basename(input_file))[0]
    
    log_func(f"ğŸš€ Báº¯t Ä‘áº§u convert: {input_file}")
    log_func(f"ğŸ¤ Giá»ng Ä‘á»c: {voice}")
    log_func(f"ğŸ“ ThÆ° má»¥c output: {output_dir}")
    log_func(f"ğŸ”§ PhÆ°Æ¡ng phÃ¡p chia: {split_method}")
    
    # Äá»c file text
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            original_text = f.read()
    except Exception as e:
        log_func(f"âŒ Lá»—i khi Ä‘á»c file: {e}")
        return ""
    
    if not original_text.strip():
        log_func("âŒ File text rá»—ng")
        return ""
    
    log_func(f"ğŸ“„ Äá»™ dÃ i text gá»‘c: {len(original_text)} kÃ½ tá»±")
    
    # LÃ m sáº¡ch text
    cleaned_text = clean_for_tts(original_text)
    log_func(f"ğŸ§¹ Äá»™ dÃ i text sau khi lÃ m sáº¡ch: {len(cleaned_text)} kÃ½ tá»±")
    
    # LÆ°u text Ä‘Ã£ lÃ m sáº¡ch
    cleaned_file = os.path.join(output_dir, f"{base_name}-cleaned.txt")
    with open(cleaned_file, 'w', encoding='utf-8') as f:
        f.write(cleaned_text)
    log_func(f"âœ… ÄÃ£ lÆ°u text lÃ m sáº¡ch: {cleaned_file}")
    
    # Chia text thÃ nh cÃ¡c pháº§n nhá»
    if split_method == "sentences":
        text_parts = split_text_by_sentences(cleaned_text, max_sentences)
        log_func(f"ğŸ“‹ Chia theo cÃ¢u: {len(text_parts)} pháº§n (tá»‘i Ä‘a {max_sentences} cÃ¢u/pháº§n)")
    else:
        text_parts = split_text_by_length(cleaned_text, max_length)
        log_func(f"ğŸ“‹ Chia theo Ä‘á»™ dÃ i: {len(text_parts)} pháº§n (tá»‘i Ä‘a {max_length} kÃ½ tá»±/pháº§n)")
    
    # Táº¡o audio cho tá»«ng pháº§n
    audio_files = []
    
    for i, part in enumerate(text_parts, 1):
        log_func(f"\nğŸŸ¡ Äang xá»­ lÃ½ pháº§n {i}/{len(text_parts)}...")
        log_func(f"ğŸ“ Äá»™ dÃ i pháº§n {i}: {len(part)} kÃ½ tá»±")
        
        # Táº¡o file audio cho pháº§n nÃ y
        part_audio = os.path.join(output_dir, f"{base_name}-part-{i:03d}.mp3")
        
        success = asyncio.run(create_audio_from_text(part, part_audio, voice))
        
        if success:
            log_func(f"âœ… ÄÃ£ táº¡o: {os.path.basename(part_audio)}")
            audio_files.append(part_audio)
        else:
            log_func(f"âŒ Lá»—i táº¡o pháº§n {i}")
        
        # Delay Ä‘á»ƒ trÃ¡nh rate limit
        time.sleep(1)
    
    if not audio_files:
        log_func("âŒ KhÃ´ng táº¡o Ä‘Æ°á»£c file audio nÃ o")
        return ""
    
    # Gá»™p táº¥t cáº£ file audio
    final_audio = os.path.join(output_dir, f"{base_name}-final.mp3")
    
    if merge_audio_files(final_audio, audio_files):
        log_func(f"\nğŸ‰ HoÃ n thÃ nh!")
        log_func(f"ğŸµ File audio cuá»‘i cÃ¹ng: {final_audio}")
        
        # TÃ­nh thá»i lÆ°á»£ng file cuá»‘i
        try:
            final_audio_segment = AudioSegment.from_file(final_audio)
            duration_seconds = len(final_audio_segment) / 1000
            duration_minutes = int(duration_seconds // 60)
            duration_seconds = int(duration_seconds % 60)
            log_func(f"â±ï¸ Thá»i lÆ°á»£ng: {duration_minutes}:{duration_seconds:02d}")
        except:
            pass
        
        # TÃ¹y chá»n: XÃ³a cÃ¡c file táº¡m
        cleanup = input("\nğŸ—‘ï¸ Báº¡n cÃ³ muá»‘n xÃ³a cÃ¡c file audio táº¡m khÃ´ng? (y/n): ").lower().strip()
        if cleanup == 'y':
            deleted = 0
            for audio_file in audio_files:
                try:
                    os.remove(audio_file)
                    deleted += 1
                except:
                    pass
            log_func(f"ğŸ—‘ï¸ ÄÃ£ xÃ³a {deleted} file táº¡m")
        
        return final_audio
    else:
        return ""

def main():
    """HÃ m main Ä‘á»ƒ cháº¡y tá»« command line"""
    print("ğŸ™ï¸ CHÆ¯Æ NG TRÃŒNH CHUYá»‚N Äá»”I TEXT-TO-SPEECH")
    print("="*50)
    
    # Nháº­p Ä‘Æ°á»ng dáº«n file
    input_file = input("ğŸ“ Nháº­p Ä‘Æ°á»ng dáº«n file txt: ").strip().strip('"')
    
    if not input_file:
        print("âŒ Vui lÃ²ng nháº­p Ä‘Æ°á»ng dáº«n file")
        return
    
    # Chá»n giá»ng Ä‘á»c
    voices = {
        "1": ("vi-VN-NamMinhNeural", "Nam Minh (Nam)"),
        "2": ("vi-VN-HoaiMyNeural", "HoÃ i My (Ná»¯)"),
        "3": ("vi-VN-TuanNeural", "Tuáº¥n (Nam)"),
        "4": ("vi-VN-VyNeural", "Vy (Ná»¯)")
    }
    
    print("\nğŸ¤ Chá»n giá»ng Ä‘á»c:")
    for key, (voice_id, voice_name) in voices.items():
        print(f"  {key}. {voice_name}")
    
    voice_choice = input("Chá»n (1-4, máº·c Ä‘á»‹nh 1): ").strip() or "1"
    selected_voice = voices.get(voice_choice, voices["1"])[0]
    
    print(f"âœ… ÄÃ£ chá»n: {voices.get(voice_choice, voices['1'])[1]}")
    
    # Chá»n phÆ°Æ¡ng phÃ¡p chia text
    print("\nğŸ”§ Chá»n phÆ°Æ¡ng phÃ¡p chia text:")
    print("  1. Theo Ä‘á»™ dÃ i kÃ½ tá»± (khuyáº¿n nghá»‹)")
    print("  2. Theo sá»‘ cÃ¢u")
    
    split_choice = input("Chá»n (1-2, máº·c Ä‘á»‹nh 1): ").strip() or "1"
    split_method = "length" if split_choice == "1" else "sentences"
    
    # Cháº¡y convert
    result = convert_text_file_to_speech(
        input_file=input_file,
        voice=selected_voice,
        split_method=split_method
    )
    
    if result:
        print(f"\nğŸŠ THÃ€NH CÃ”NG! File audio Ä‘Ã£ Ä‘Æ°á»£c táº¡o táº¡i: {result}")
    else:
        print("\nğŸ’¥ CÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i")
    
    input("\nNháº¥n Enter Ä‘á»ƒ thoÃ¡t...")

if __name__ == "__main__":
    main()