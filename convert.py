import requests
import time
import traceback
import re
import asyncio
import edge_tts
import unicodedata
from pydub import AudioSegment
import os
import sys
import json

# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n ffmpeg khi ƒë√≥ng g√≥i
if getattr(sys, 'frozen', False):
    base_path = sys._MEIPASS
    ffmpeg_path = os.path.join(base_path, "ffmpeg.exe")
else:
    # C·∫ßn ƒë·∫£m b·∫£o ffmpeg.exe c√≥ trong PATH ho·∫∑c c√πng th∆∞ m·ª•c v·ªõi script
    ffmpeg_path = "ffmpeg.exe"
AudioSegment.converter = ffmpeg_path

MODEL = "deepseek/deepseek-r1:free" # S·ª≠ d·ª•ng model m√† b·∫°n ƒë√£ ch·ªâ ƒë·ªãnh
API_URL = "https://openrouter.ai/api/v1/chat/completions"

def slugify(text: str) -> str:
    # Chuy·ªÉn Unicode v·ªÅ ASCII, lowercase, thay k√Ω t·ª± kh√¥ng alnum th√†nh d·∫•u '-'
    text = unicodedata.normalize('NFD', text)
    text = text.encode('ascii', 'ignore').decode('utf-8')
    text = text.lower()
    text = re.sub(r'[^a-z0-9]+', '-', text)
    return text.strip('-')

def clean_for_tts(text: str) -> str:
    """
    L√†m s·∫°ch vƒÉn b·∫£n ƒë·ªÉ chuy·ªÉn sang TTS:
    - Gi·ªØ l·∫°i ch·ªØ c√°i (c·∫£ ti·∫øng Vi·ªát), s·ªë v√† d·∫•u c√¢u c∆° b·∫£n
    - Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, d·∫•u ngo·∫∑c, markdown...
    """
    import unicodedata

    # Chu·∫©n h√≥a Unicode ƒë·ªÉ tr√°nh k√Ω t·ª± l·∫°
    text = unicodedata.normalize('NFKC', text)

    # Lo·∫°i b·ªè markdown ** ** ho·∫∑c * *
    text = re.sub(r"\*\*.*?\*\*", "", text)
    text = re.sub(r"\*.*?\*", "", text)

    # X√≥a n·ªôi dung trong ngo·∫∑c tr√≤n ( ), vu√¥ng [ ], nh·ªçn < >, ngo·∫∑c k√©p
    text = re.sub(r"[\(\)\[\]\{\}<>\"""''']", "", text)

    # X√≥a c√°c h∆∞·ªõng d·∫´n nh∆∞ "Camera:..." ho·∫∑c "--- PH·∫¶N X ---"
    text = re.sub(r"Camera.*?\.", "", text)
    text = re.split(r"(?m)^(N·∫øu b·∫°n mu·ªën|---\s*PH·∫¶N\s*\d+\s*---)", text)[0]

    # Ch·ªâ gi·ªØ l·∫°i c√°c k√Ω t·ª± h·ª£p l·ªá cho TTS: ch·ªØ c√°i (c√≥ d·∫•u), s·ªë v√† d·∫•u c√¢u th∆∞·ªùng
    # Regex n√†y gi·ªØ l·∫°i c√°c k√Ω t·ª± ti·∫øng Vi·ªát, ch·ªØ c√°i Latin, s·ªë, d·∫•u c√¢u c∆° b·∫£n v√† kho·∫£ng tr·∫Øng
    text = re.sub(r"[^a-zA-Z√Ä-·ªπ0-9\s\.,!?:;\-‚Ä¶]", "", text)

    # R√∫t g·ªçn kho·∫£ng tr·∫Øng
    text = re.sub(r"\s+", " ", text).strip()

    return text

async def create_audio_from_text(text: str, output_path: str, voice: str = "vi-VN-HoaiMyNeural"):
    communicate = edge_tts.Communicate(text=text, voice=voice)
    await communicate.save(output_path)

def merge_audio_files(output_file: str, pattern: str, num_parts: int):
    print("\nüîÑ ƒêang g·ªôp c√°c ph·∫ßn √¢m thanh l·∫°i th√†nh 1 file...")
    merged = AudioSegment.empty()
    for i in range(num_parts):
        part_file = pattern.format(i + 1)
        if os.path.exists(part_file):
            audio = AudioSegment.from_file(part_file, format="mp3")
            merged += audio
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y: {part_file}, b·ªè qua.")
    merged.export(output_file, format="mp3")
    print(f"‚úÖ ƒê√£ t·∫°o file g·ªôp: {output_file}")

def parse_detailed_outline(outline_content: str) -> list:
    """
    Parse detailed outline from JSON format or fallback to simple parsing
    """
    try:
        # Try to parse as JSON first
        outline_data = json.loads(outline_content)
        if isinstance(outline_data, list):
            return outline_data
        elif isinstance(outline_data, dict) and 'outline' in outline_data:
            return outline_data['outline']
    except:
        pass
    
    # Fallback to simple parsing
    outline_points = []
    lines = outline_content.split('\n')
    current_section = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Check if it's a numbered section (1., 2., etc.)
        if re.match(r'^\d+\.', line):
            if current_section:
                outline_points.append(current_section)
            current_section = {
                'title': line,
                'content': '',
                'key_points': [],
                'emotion': '',
                'transition': ''
            }
        elif current_section and line:
            # Add content to current section
            if current_section['content']:
                current_section['content'] += ' ' + line
            else:
                current_section['content'] = line
    
    # Add the last section
    if current_section:
        outline_points.append(current_section)
    
    return outline_points

def run_convert(
    topic: str,
    api_key: str,
    num_parts: int = 12,
    log_func=print,
    voice: str = "vi-VN-HoaiMyNeural"
) -> str:
    log_func(f"üöÄ B·∫Øt ƒë·∫ßu ch·∫°y v·ªõi ch·ªß ƒë·ªÅ: {topic}")
    log_func(f"üîë D√πng API key: {api_key[:6]}***")
    log_func(f"üìÑ S·ªë ph·∫ßn d·ª± ki·∫øn: {num_parts}")

    HEADERS = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    base = slugify(topic)
    output_dir = os.path.join("output", base)
    os.makedirs(output_dir, exist_ok=True)

    output_script = os.path.join(output_dir, f"{base}.txt")
    output_clean = os.path.join(output_dir, f"{base}-clean.txt")
    output_outline = os.path.join(output_dir, f"{base}-outline.txt")

    # Clear previous output files if they exist for a fresh run
    for file_path in [output_script, output_clean, output_outline]:
        if os.path.exists(file_path):
            os.remove(file_path)

    def call_openrouter(messages):
        try:
            data = {"model": MODEL, "messages": messages}
            res = requests.post(API_URL, headers=HEADERS, json=data)
            if res.status_code != 200:
                log_func(f"‚ùå HTTP {res.status_code} - {res.text}")
                return None
            return res.json()["choices"][0]["message"]["content"]
        except Exception:
            log_func("‚ùå L·ªói khi g·ªçi API:")
            log_func(traceback.format_exc())
            return None

    # Step 1: Generate a detailed story outline
    log_func("\nüìù ƒêang t·∫°o d√†n √Ω c√¢u chuy·ªán chi ti·∫øt...")
    outline_prompt = f"""
D·ª±a tr√™n ch·ªß ƒë·ªÅ: '{topic}', h√£y t·∫°o m·ªôt d√†n √Ω c√¢u chuy·ªán c·∫£m ƒë·ªông C·ª∞C K·ª≤ CHI TI·∫æT ƒë·ªÉ chia th√†nh {num_parts} ph√¢n ƒëo·∫°n.

QUAN TR·ªåNG: M·ªói ph√¢n ƒëo·∫°n ph·∫£i c√≥:
1. Ti√™u ƒë·ªÅ r√µ r√†ng
2. N·ªôi dung c·ª• th·ªÉ c·∫ßn k·ªÉ (3-5 c√¢u m√¥ t·∫£ chi ti·∫øt)
3. C·∫£m x√∫c ch√≠nh c·∫ßn truy·ªÅn t·∫£i
4. C√°ch chuy·ªÉn ti·∫øp sang ph·∫ßn ti·∫øp theo
5. Nh√¢n v·∫≠t v√† t√¨nh hu·ªëng c·ª• th·ªÉ (n·∫øu c√≥)

ƒê·ªãnh d·∫°ng tr·∫£ v·ªÅ:
```
1. [Ti√™u ƒë·ªÅ ph·∫ßn 1]
   N·ªôi dung: [M√¥ t·∫£ c·ª• th·ªÉ 3-5 c√¢u v·ªÅ nh·ªØng g√¨ s·∫Ω k·ªÉ trong ph·∫ßn n√†y]
   C·∫£m x√∫c: [C·∫£m x√∫c ch√≠nh c·∫ßn truy·ªÅn t·∫£i]
   Chuy·ªÉn ti·∫øp: [C√°ch d·∫´n d·∫Øt sang ph·∫ßn ti·∫øp theo]

2. [Ti√™u ƒë·ªÅ ph·∫ßn 2]
   N·ªôi dung: [M√¥ t·∫£ c·ª• th·ªÉ...]
   C·∫£m x√∫c: [...]
   Chuy·ªÉn ti·∫øp: [...]

...v√† ti·∫øp t·ª•c cho ƒë·∫øn ph·∫ßn {num_parts}
```

ƒê·∫£m b·∫£o:
- Logic li√™n k·∫øt ch·∫∑t ch·∫Ω gi·ªØa c√°c ph·∫ßn
- M·ªói ph·∫ßn c√≥ m·ª•c ƒë√≠ch r√µ r√†ng trong t·ªïng th·ªÉ c√¢u chuy·ªán
- Cung c·∫•p ƒë·ªß chi ti·∫øt ƒë·ªÉ vi·∫øt t·ª´ng ph·∫ßn m√† kh√¥ng b·ªã l·∫°c ch·ªß ƒë·ªÅ
- C·ªët truy·ªán ph·∫£i c√≥ cung b·∫≠c c·∫£m x√∫c r√µ r√†ng (m·ªü ƒë·∫ßu ‚Üí ph√°t tri·ªÉn ‚Üí cao tr√†o ‚Üí k·∫øt th√∫c)
"""

    outline_messages = [
        {
            "role": "system",
            "content": (
                "B·∫°n l√† tr·ª£ l√Ω chuy√™n t·∫°o d√†n √Ω k·ªãch b·∫£n chi ti·∫øt. "
                "Ph·∫£i t·∫°o d√†n √Ω C·ª∞C K·ª≤ CHI TI·∫æT ƒë·ªÉ ng∆∞·ªùi vi·∫øt c√≥ th·ªÉ d·ªÖ d√†ng tri·ªÉn khai t·ª´ng ph·∫ßn "
                "m√† kh√¥ng b·ªã l·∫°c ch·ªß ƒë·ªÅ ho·∫∑c thi·∫øu logic li√™n k·∫øt."
            )
        },
        {"role": "user", "content": outline_prompt}
    ]
    
    outline_content = call_openrouter(outline_messages)
    if not outline_content:
        log_func("‚ùå Kh√¥ng th·ªÉ t·∫°o d√†n √Ω. D·ª´ng ch∆∞∆°ng tr√¨nh.")
        return ""
    
    # Save detailed outline
    with open(output_outline, "w", encoding="utf-8") as f:
        f.write(f"D√ÄN √ù CHI TI·∫æT CHO: {topic}\n")
        f.write("="*50 + "\n\n")
        f.write(outline_content)
    
    log_func("‚úÖ ƒê√£ t·∫°o d√†n √Ω chi ti·∫øt, l∆∞u t·∫°i: " + output_outline)
    
    # Parse the detailed outline
    outline_sections = parse_detailed_outline(outline_content)
    if not outline_sections:
        # Fallback parsing for non-JSON format
        sections = re.split(r'\n(?=\d+\.)', outline_content.strip())
        outline_sections = []
        for section in sections:
            if section.strip():
                lines = section.strip().split('\n')
                title = lines[0] if lines else ""
                content = '\n'.join(lines[1:]) if len(lines) > 1 else ""
                outline_sections.append({
                    'title': title,
                    'content': content,
                    'full_text': section.strip()
                })
    
    log_func(f"üìã ƒê√£ ph√¢n t√≠ch {len(outline_sections)} ph·∫ßn trong d√†n √Ω")
    
    # Store the full story text to pass context between parts
    full_story_text = ""
    
    for i in range(num_parts):
        log_func(f"\nüü° ƒêang vi·∫øt ph·∫ßn {i+1}/{num_parts}...")
        
        # Get the specific outline section for this part
        if i < len(outline_sections):
            current_section = outline_sections[i]
            section_guide = current_section.get('full_text', current_section.get('content', ''))
        else:
            # If we have fewer outline sections than num_parts, use the last one
            current_section = outline_sections[-1] if outline_sections else {}
            section_guide = "Ti·∫øp t·ª•c ph√°t tri·ªÉn c√¢u chuy·ªán theo logic t·ª± nhi√™n"
        
        # Prepare context from previous parts (last 1500 chars to manage tokens)
        context_text = full_story_text[-1500:] if full_story_text else ""
        
        # Create detailed prompt based on part position
        if i == 0:
            user_prompt_content = f"""
Vi·∫øt ph·∫ßn m·ªü ƒë·∫ßu c·ªßa c√¢u chuy·ªán d·ª±a tr√™n ch·ªß ƒë·ªÅ: '{topic}'

H∆Ø·ªöNG D·∫™N CHI TI·∫æT CHO PH·∫¶N N√ÄY:
{section_guide}

Y√äU C·∫¶U VI·∫æT:
- Kho·∫£ng 500 t·ª´
- Gi·ªçng vƒÉn t·ª± s·ª±, c·∫£m x√∫c, thu h√∫t ng∆∞·ªùi nghe
- TU√ÇN TH·ª¶ CH·∫∂T CH·∫º n·ªôi dung trong h∆∞·ªõng d·∫´n tr√™n
- KH√îNG l·ªách kh·ªèi ch·ªß ƒë·ªÅ ho·∫∑c th√™m th√¥ng tin kh√¥ng li√™n quan
- KH√îNG s·ª≠ d·ª•ng k√Ω hi·ªáu ƒë·∫∑c bi·ªát, d·∫•u ngo·∫∑c, markdown
- Ch·ªâ d√πng d·∫•u c√¢u th√¥ng th∆∞·ªùng: . , ! ? : ;

Ch·ªâ tr·∫£ v·ªÅ n·ªôi dung c√¢u chuy·ªán, kh√¥ng th√™m gi·∫£i th√≠ch hay meta.
"""
        elif i == num_parts - 1:
            user_prompt_content = f"""
Vi·∫øt ph·∫ßn k·∫øt th√∫c c·ªßa c√¢u chuy·ªán d·ª±a tr√™n ch·ªß ƒë·ªÅ: '{topic}'

H∆Ø·ªöNG D·∫™N CHI TI·∫æT CHO PH·∫¶N N√ÄY:
{section_guide}

N·ªêI TI·∫æP T·ª™ PH·∫¶N TR∆Ø·ªöC:
{context_text}

Y√äU C·∫¶U VI·∫æT:
- Kho·∫£ng 500 t·ª´
- K·∫øt th√∫c c√≥ √Ω nghƒ©a, c·∫£m ƒë·ªông
- TU√ÇN TH·ª¶ CH·∫∂T CH·∫º n·ªôi dung trong h∆∞·ªõng d·∫´n
- N·ªëi ti·∫øp t·ª± nhi√™n t·ª´ ph·∫ßn tr∆∞·ªõc, KH√îNG l·∫∑p l·∫°i n·ªôi dung
- KH√îNG s·ª≠ d·ª•ng k√Ω hi·ªáu ƒë·∫∑c bi·ªát, d·∫•u ngo·∫∑c, markdown
- Ch·ªâ d√πng d·∫•u c√¢u th√¥ng th∆∞·ªùng

Ch·ªâ tr·∫£ v·ªÅ n·ªôi dung c√¢u chuy·ªán, kh√¥ng th√™m gi·∫£i th√≠ch hay meta.
"""
        else:
            user_prompt_content = f"""
Vi·∫øt ti·∫øp ph·∫ßn {i+1} c·ªßa c√¢u chuy·ªán d·ª±a tr√™n ch·ªß ƒë·ªÅ: '{topic}'

H∆Ø·ªöNG D·∫™N CHI TI·∫æT CHO PH·∫¶N N√ÄY:
{section_guide}

N·ªêI TI·∫æP T·ª™ PH·∫¶N TR∆Ø·ªöC:
{context_text}

Y√äU C·∫¶U VI·∫æT:
- Kho·∫£ng 500 t·ª´
- TU√ÇN TH·ª¶ CH·∫∂T CH·∫º n·ªôi dung trong h∆∞·ªõng d·∫´n tr√™n
- N·ªëi ti·∫øp t·ª± nhi√™n t·ª´ ph·∫ßn tr∆∞·ªõc, KH√îNG l·∫∑p l·∫°i n·ªôi dung
- Ph√°t tri·ªÉn c√¢u chuy·ªán theo ƒë√∫ng h∆∞·ªõng ƒë√£ ƒë·ªãnh
- KH√îNG s·ª≠ d·ª•ng k√Ω hi·ªáu ƒë·∫∑c bi·ªát, d·∫•u ngo·∫∑c, markdown
- Ch·ªâ d√πng d·∫•u c√¢u th√¥ng th∆∞·ªùng

Ch·ªâ tr·∫£ v·ªÅ n·ªôi dung c√¢u chuy·ªán, kh√¥ng th√™m gi·∫£i th√≠ch hay meta.
"""

        messages = [
            {
                "role": "system",
                "content": (
                    "B·∫°n l√† tr·ª£ l√Ω vi·∫øt k·ªãch b·∫£n chuy√™n nghi·ªáp. "
                    "PH·∫¢I tu√¢n th·ªß ch·∫∑t ch·∫Ω h∆∞·ªõng d·∫´n ƒë∆∞·ª£c cung c·∫•p. "
                    "KH√îNG ƒë∆∞·ª£c l·ªách ch·ªß ƒë·ªÅ ho·∫∑c t·ª± √Ω th√™m n·ªôi dung kh√¥ng li√™n quan. "
                    "CH·ªà tr·∫£ v·ªÅ n·ªôi dung c√¢u chuy·ªán, kh√¥ng th√™m b·∫•t k·ª≥ meta hay gi·∫£i th√≠ch n√†o."
                )
            },
            {"role": "user", "content": user_prompt_content}
        ]

        reply = call_openrouter(messages)
        
        if not reply or len(reply.strip()) < 50:
            log_func(f"‚ö†Ô∏è Ph·∫ßn {i+1} r·ªóng ho·∫∑c qu√° ng·∫Øn, b·ªè qua.")
            continue
        
        log_func(f"‚úÖ ƒê√£ vi·∫øt xong ph·∫ßn {i+1}. ƒêang x·ª≠ l√Ω...")
        
        # Update full story context
        full_story_text += reply.strip() + "\n"

        # Save raw content
        with open(output_script, "a", encoding="utf-8") as f:
            f.write(f"\n--- PH·∫¶N {i+1} ---\n")
            f.write(reply.strip() + "\n")

        # Clean and save for TTS
        cleaned = clean_for_tts(reply)
        with open(output_clean, "a", encoding="utf-8") as f: 
            f.write(f"\n--- PH·∫¶N {i+1} ---\n")
            f.write(cleaned + "\n")

        # Generate audio
        audio_file = os.path.join(output_dir, f"{base}-part-{i+1}.mp3")
        asyncio.run(create_audio_from_text(cleaned, audio_file, voice))
        log_func(f"üéß ƒê√£ t·∫°o file √¢m thanh: {audio_file}")

        time.sleep(10)  # Rate limiting

    # Merge all audio files
    final_audio = os.path.join(output_dir, f"{base}-final.mp3")
    merge_audio_files(
        final_audio,
        os.path.join(output_dir, f"{base}-part-{{}}.mp3"),
        num_parts
    )
    
    log_func(f"\nüéâ Ho√†n t·∫•t!")
    log_func(f"üìÑ D√†n √Ω chi ti·∫øt: {output_outline}")
    log_func(f"üìù K·ªãch b·∫£n g·ªëc: {output_script}")
    log_func(f"üßπ K·ªãch b·∫£n clean: {output_clean}")
    log_func(f"üéµ Audio ho√†n ch·ªânh: {final_audio}")
    
    return final_audio


if __name__ == "__main__":
    TEST_KEY = "sk-or-v1-your_api_key_here"  # Thay th·∫ø b·∫±ng API key th·∫≠t c·ªßa b·∫°n
    TEST_TOPIC = "T·∫°i Sao Nh·∫≠t B·∫£n G·∫ßn Nh∆∞ Kh√¥ng C√≥ Tr·ªôm C·∫Øp?"
    
    # Test v·ªõi 25 ph·∫ßn nh∆∞ b·∫°n th∆∞·ªùng y√™u c·∫ßu
    run_convert(TEST_TOPIC, TEST_KEY, num_parts=25)