import requests
import time
import traceback
import re
import asyncio
import edge_tts
import unicodedata
from pydub import AudioSegment
import os
import sys

# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n ffmpeg khi ƒë√≥ng g√≥i
if getattr(sys, 'frozen', False):
    base_path = sys._MEIPASS
    ffmpeg_path = os.path.join(base_path, "ffmpeg.exe")
else:
    # C·∫ßn ƒë·∫£m b·∫£o ffmpeg.exe c√≥ trong PATH ho·∫∑c c√πng th∆∞ m·ª•c v·ªõi script
    ffmpeg_path = "ffmpeg.exe"
AudioSegment.converter = ffmpeg_path

MODEL = "deepseek/deepseek-r1:free" # S·ª≠ d·ª•ng model m√† b·∫°n ƒë√£ ch·ªâ ƒë·ªãnh
API_URL = "https://openrouter.ai/api/v1/chat/completions"

def slugify(text: str) -> str:
    # Chuy·ªÉn Unicode v·ªÅ ASCII, lowercase, thay k√Ω t·ª± kh√¥ng alnum th√†nh d·∫•u '-'
    text = unicodedata.normalize('NFD', text)
    text = text.encode('ascii', 'ignore').decode('utf-8')
    text = text.lower()
    text = re.sub(r'[^a-z0-9]+', '-', text)
    return text.strip('-')

def clean_for_tts(text: str) -> str:
    """
    L√†m s·∫°ch vƒÉn b·∫£n ƒë·ªÉ chuy·ªÉn sang TTS:
    - Gi·ªØ l·∫°i ch·ªØ c√°i (c·∫£ ti·∫øng Vi·ªát), s·ªë v√† d·∫•u c√¢u c∆° b·∫£n
    - Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, d·∫•u ngo·∫∑c, markdown...
    """
    import unicodedata

    # Chu·∫©n h√≥a Unicode ƒë·ªÉ tr√°nh k√Ω t·ª± l·∫°
    text = unicodedata.normalize('NFKC', text)

    # Lo·∫°i b·ªè markdown ** ** ho·∫∑c * *
    text = re.sub(r"\*\*.*?\*\*", "", text)
    text = re.sub(r"\*.*?\*", "", text)

    # X√≥a n·ªôi dung trong ngo·∫∑c tr√≤n ( ), vu√¥ng [ ], nh·ªçn < >, ngo·∫∑c k√©p
    text = re.sub(r"[\(\)\[\]\{\}<>\"‚Äú‚Äù‚Äò‚Äô']", "", text)

    # X√≥a c√°c h∆∞·ªõng d·∫´n nh∆∞ "Camera:..." ho·∫∑c "--- PH·∫¶N X ---"
    text = re.sub(r"Camera.*?\.", "", text)
    text = re.split(r"(?m)^(N·∫øu b·∫°n mu·ªën|---\s*PH·∫¶N\s*\d+\s*---)", text)[0]

    # Ch·ªâ gi·ªØ l·∫°i c√°c k√Ω t·ª± h·ª£p l·ªá cho TTS: ch·ªØ c√°i (c√≥ d·∫•u), s·ªë v√† d·∫•u c√¢u th∆∞·ªùng
    # Regex n√†y gi·ªØ l·∫°i c√°c k√Ω t·ª± ti·∫øng Vi·ªát, ch·ªØ c√°i Latin, s·ªë, d·∫•u c√¢u c∆° b·∫£n v√† kho·∫£ng tr·∫Øng
    text = re.sub(r"[^a-zA-Z√Ä-·ªπ0-9\s\.,!?:;\-‚Ä¶]", "", text)


    # R√∫t g·ªçn kho·∫£ng tr·∫Øng
    text = re.sub(r"\s+", " ", text).strip()

    return text

async def create_audio_from_text(text: str, output_path: str, voice: str = "vi-VN-HoaiMyNeural"):
    communicate = edge_tts.Communicate(text=text, voice=voice)
    await communicate.save(output_path)

def merge_audio_files(output_file: str, pattern: str, num_parts: int):
    print("\nüîÑ ƒêang g·ªôp c√°c ph·∫ßn √¢m thanh l·∫°i th√†nh 1 file...")
    merged = AudioSegment.empty()
    for i in range(num_parts):
        part_file = pattern.format(i + 1)
        if os.path.exists(part_file):
            audio = AudioSegment.from_file(part_file, format="mp3")
            merged += audio
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y: {part_file}, b·ªè qua.")
    merged.export(output_file, format="mp3")
    print(f"‚úÖ ƒê√£ t·∫°o file g·ªôp: {output_file}")


def run_convert(
    topic: str,
    api_key: str,
    num_parts: int = 12, # Changed default from 12 to 25 as per user's typical request for 25 sections.
    log_func=print,
    voice: str = "vi-VN-HoaiMyNeural"
) -> str:
    log_func(f"üöÄ B·∫Øt ƒë·∫ßu ch·∫°y v·ªõi ch·ªß ƒë·ªÅ: {topic}")
    log_func(f"üîë D√πng API key: {api_key[:6]}***")
    log_func(f"üìÑ S·ªë ph·∫ßn d·ª± ki·∫øn: {num_parts}")

    HEADERS = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    base = slugify(topic)
    output_dir = os.path.join("output", base)
    os.makedirs(output_dir, exist_ok=True)

    output_script = os.path.join(output_dir, f"{base}.txt")
    output_clean = os.path.join(output_dir, f"{base}-clean.txt")

    # Clear previous output files if they exist for a fresh run
    if os.path.exists(output_script):
        os.remove(output_script)
    if os.path.exists(output_clean):
        os.remove(output_clean)


    def call_openrouter(messages):
        try:
            data = {"model": MODEL, "messages": messages}
            res = requests.post(API_URL, headers=HEADERS, json=data)
            if res.status_code != 200:
                log_func(f"‚ùå HTTP {res.status_code} - {res.text}")
                return None
            return res.json()["choices"][0]["message"]["content"]
        except Exception:
            log_func("‚ùå L·ªói khi g·ªçi API:")
            log_func(traceback.format_exc())
            return None

    # Step 1: Generate a story outline
    log_func("\nüìù ƒêang t·∫°o d√†n √Ω c√¢u chuy·ªán...")
    outline_prompt = (
        f"D·ª±a tr√™n ch·ªß ƒë·ªÅ: '{topic}', h√£y t·∫°o m·ªôt d√†n √Ω c√¢u chuy·ªán c·∫£m ƒë·ªông, chi ti·∫øt, "
        f"ph√π h·ª£p ƒë·ªÉ chia th√†nh {num_parts} ph√¢n ƒëo·∫°n ri√™ng bi·ªát v√† li·ªÅn m·∫°ch. "
        "M·ªói ph√¢n ƒëo·∫°n n√™n c√≥ m·ªôt m·ª•c ƒë√≠ch r√µ r√†ng v√† th√∫c ƒë·∫©y c·ªët truy·ªán m·ªôt c√°ch t·ª± nhi√™n. "
        "Cung c·∫•p d√†n √Ω d∆∞·ªõi d·∫°ng danh s√°ch ƒë∆∞·ª£c ƒë√°nh s·ªë li√™n t·ª•c t·ª´ 1 ƒë·∫øn N (v√≠ d·ª•: 1., 2., 3., ...) "
        "m√† KH√îNG c√≥ b·∫•t k·ª≥ l·ªùi m·ªü ƒë·∫ßu, k·∫øt th√∫c, ho·∫∑c ƒë√°nh s·ªë tr√πng l·∫∑p n√†o. "
        "Ch·ªâ ƒë√°nh s·ªë m·ªôt l·∫ßn cho m·ªói m·ª•c. T·∫≠p trung v√†o m·ªôt v√≤ng cung t·ª± s·ª± m·∫°nh m·∫Ω."
    )
    outline_messages = [
        {
            "role": "system",
            "content": (
                "B·∫°n l√† tr·ª£ l√Ω chuy√™n vi·∫øt d√†n √Ω c·ªët truy·ªán. "
                "KH√îNG ƒë∆∞·ª£c th√™m b·∫•t k·ª≥ ph·∫ßn t√≥m t·∫Øt, ph√¢n t√≠ch, g·ª£i √Ω hay meta n√†o."
            )
        },
        {"role": "user", "content": outline_prompt}
    ]
    
    outline_content = call_openrouter(outline_messages)
    if not outline_content:
        log_func("‚ùå Kh√¥ng th·ªÉ t·∫°o d√†n √Ω. D·ª´ng ch∆∞∆°ng tr√¨nh.")
        return ""
    
    # Parse the outline (simple split by new line and filter empty lines)
    outline_points = [point.strip() for point in outline_content.split('\n') if point.strip()]
    if not outline_points:
        log_func("‚ùå D√†n √Ω tr·ªëng r·ªóng. D·ª´ng ch∆∞∆°ng tr√¨nh.")
        return ""

    log_func("‚úÖ ƒê√£ t·∫°o d√†n √Ω:")
    for i, point in enumerate(outline_points):
        log_func(f"   {i+1}. {point}")
    
    # Store the full story text to pass the last part as context
    full_story_text = ""

    for i in range(num_parts):
        log_func(f"\nüü° ƒêang l·∫•y ph·∫ßn {i+1}/{num_parts}...")
        
        # Determine the specific outline point for this part
        current_outline_point = outline_points[min(i, len(outline_points) - 1)] # Handle cases where num_parts > outline_points
        
        # Prepare the context from the previous segment (last 2000 chars to manage tokens)
        last_generated_segment_text = full_story_text[-2000:] if full_story_text else ""

        user_prompt_content = ""
        if i == 0:
            user_prompt_content = (
                f"Vi·∫øt ph·∫ßn m·ªü ƒë·∫ßu c·ªßa c√¢u chuy·ªán c·∫£m ƒë·ªông v·ªõi ch·ªß ƒë·ªÅ: '{topic}'.\n"
                f"Ph·∫ßn n√†y c·∫ßn t·∫≠p trung v√†o: '{current_outline_point}'.\n\n"
                "Y√™u c·∫ßu:\n"
                "- Vi·∫øt gi·ªçng vƒÉn t·ª± s·ª±, c·∫£m x√∫c, kho·∫£ng 500 t·ª´.\n"
                "- KH√îNG s·ª≠ d·ª•ng b·∫•t k·ª≥ k√Ω hi·ªáu ƒë·∫∑c bi·ªát, d·∫•u ngo·∫∑c k√©p, d·∫•u ngo·∫∑c ƒë∆°n, ho·∫∑c d·∫•u ngo·∫∑c tr√≤n.\n"
                "- KH√îNG d√πng markdown (*, **, #, v.v.)\n"
                "- Gi·ªØ l·∫°i d·∫•u ch·∫•m, ph·∫©y, ch·∫•m than, ch·∫•m h·ªèi v√† c√°c d·∫•u c√¢u th√¥ng th∆∞·ªùng.\n"
                "- Tr·∫£ v·ªÅ n·ªôi dung thu·∫ßn vƒÉn b·∫£n, s·∫°ch, kh√¥ng ƒë·ªãnh d·∫°ng ho·∫∑c ch√∫ th√≠ch th√™m.\n\n"
                "Ch·ªâ tr·∫£ l·∫°i n·ªôi dung k·ªãch b·∫£n, kh√¥ng th√™m ph·∫ßn meta ho·∫∑c h∆∞·ªõng d·∫´n."
            )
        elif i == num_parts - 1:
            user_prompt_content = (
                f"Vi·∫øt ph·∫ßn k·∫øt c·ªßa c√¢u chuy·ªán, k·∫øt b·∫±ng c·∫£m x√∫c s√¢u l·∫Øng, kho·∫£ng 500 t·ª´, d·ª±a tr√™n ch·ªß ƒë·ªÅ: '{topic}'.\n"
                f"Ph·∫ßn n√†y c·∫ßn t·∫≠p trung v√†o: '{current_outline_point}'.\n"
                f"D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n k·∫øt th√∫c c·ªßa ph·∫ßn tr∆∞·ªõc. H√£y k·∫øt th√∫c c√¢u chuy·ªán T·ª™ ƒê√ÇY v√† ph√°t tri·ªÉn n·ªôi dung cu·ªëi c√πng:\n"
                f"---\n{last_generated_segment_text}\n---\n\n"
                "Y√™u c·∫ßu gi·ªëng nh∆∞ c√°c ph·∫ßn tr∆∞·ªõc:\n"
                "- KH√îNG s·ª≠ d·ª•ng d·∫•u ngo·∫∑c, markdown ho·∫∑c k√Ω hi·ªáu ƒë·∫∑c bi·ªát.\n"
                "- Ch·ªâ tr·∫£ l·∫°i vƒÉn b·∫£n s·∫°ch v·ªõi d·∫•u c√¢u th√¥ng th∆∞·ªùng.\n"
                "Ch·ªâ tr·∫£ l·∫°i n·ªôi dung k·ªãch b·∫£n, kh√¥ng th√™m ph·∫ßn meta ho·∫∑c h∆∞·ªõng d·∫´n."
            )
        else:
            user_prompt_content = (
                f"Vi·∫øt ti·∫øp ph·∫ßn th√¢n c·ªßa c√¢u chuy·ªán (li·ªÅn m·∫°ch, KH√îNG l·∫∑p l·∫°i n·ªôi dung ƒë√£ c√≥), kho·∫£ng 500 t·ª´, d·ª±a tr√™n ch·ªß ƒë·ªÅ: '{topic}'.\n"
                f"Ph·∫ßn n√†y c·∫ßn t·∫≠p trung v√†o: '{current_outline_point}'.\n"
                f"D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n k·∫øt th√∫c c·ªßa ph·∫ßn tr∆∞·ªõc. H√£y ti·∫øp t·ª•c c√¢u chuy·ªán T·ª™ ƒê√ÇY v√† ph√°t tri·ªÉn n·ªôi dung m·ªõi:\n"
                f"---\n{last_generated_segment_text}\n---\n\n"
                "Y√™u c·∫ßu gi·ªëng nh∆∞ c√°c ph·∫ßn tr∆∞·ªõc:\n"
                "- KH√îNG s·ª≠ d·ª•ng d·∫•u ngo·∫∑c, markdown ho·∫∑c k√Ω hi·ªáu ƒë·∫∑c bi·ªát.\n"
                "- Ch·ªâ tr·∫£ l·∫°i vƒÉn b·∫£n s·∫°ch v·ªõi d·∫•u c√¢u th√¥ng th∆∞·ªùng.\n"
                "Ch·ªâ tr·∫£ l·∫°i n·ªôi dung k·ªãch b·∫£n, kh√¥ng th√™m ph·∫ßn meta ho·∫∑c h∆∞·ªõng d·∫´n."
            )

        # The system message remains consistent to enforce content type
        messages = [
            {
                "role": "system",
                "content": (
                    "B·∫°n l√† tr·ª£ l√Ω chuy√™n vi·∫øt k·ªãch b·∫£n k·ªÉ chuy·ªán. "
                    "KH√îNG ƒë∆∞·ª£c th√™m b·∫•t k·ª≥ ph·∫ßn t√≥m t·∫Øt, ph√¢n t√≠ch, g·ª£i √Ω hay meta n√†o."
                )
            },
            {"role": "user", "content": user_prompt_content}
        ]

        reply = call_openrouter(messages)
        
        if not reply or len(reply.strip()) < 50:
            log_func(f"‚ö†Ô∏è Ph·∫ßn {i+1} r·ªóng ho·∫∑c qu√° ng·∫Øn, b·ªè qua.")
            # Important: if reply is empty/short, do not add it to full_story_text or messages
            # This ensures that the next part's context is not based on a bad segment.
            # A more robust solution might involve retrying the API call or adjusting num_parts dynamically.
            continue
        
        log_func(f"‚úÖ ƒê√£ nh·∫≠n ph·∫ßn {i+1}. ƒêang x·ª≠ l√Ω...")
        
        # Append the generated part to the full story text for context in subsequent calls
        full_story_text += reply.strip() + "\n"

        with open(output_script, "a", encoding="utf-8") as f:
            f.write(f"\n--- PH·∫¶N {i+1} ---\n")
            f.write(reply.strip() + "\n")

        cleaned = clean_for_tts(reply)
        with open(output_clean, "a", encoding="utf-8") as f: 
            f.write(f"\n--- PH·∫¶N {i+1} ---\n")
            f.write(cleaned + "\n")

        audio_file = os.path.join(output_dir, f"{base}-part-{i+1}.mp3")
        asyncio.run(create_audio_from_text(cleaned, audio_file, voice))
        log_func(f"üéß ƒê√£ t·∫°o file √¢m thanh: {audio_file}")

        time.sleep(10) # Add a delay to avoid hitting rate limits

    final_audio = os.path.join(output_dir, f"{base}-final.mp3")
    merge_audio_files(
        final_audio,
        os.path.join(output_dir, f"{base}-part-{{}}.mp3"),
        num_parts
    )
    log_func(f"\nüéâ Ho√†n t·∫•t. Audio g·ªôp t·∫°i: {final_audio}")
    return final_audio


if __name__ == "__main__":
    TEST_KEY = "sk-or-v1-your_api_key_here" # Thay th·∫ø b·∫±ng API key th·∫≠t c·ªßa b·∫°n
    TEST_TOPIC = "T·∫°i Sao Nh·∫≠t B·∫£n G·∫ßn Nh∆∞ Kh√¥ng C√≥ Tr·ªôm C·∫Øp?"
    # ƒê·ªÉ th·ª≠ v·ªõi 25 ph·∫ßn nh∆∞ b·∫°n mong mu·ªën, b·∫°n c√≥ th·ªÉ g·ªçi:
    # run_convert(TEST_TOPIC, TEST_KEY, num_parts=25)
    # Ho·∫∑c ƒë·ªÉ nguy√™n m·∫∑c ƒë·ªãnh 12 ph·∫ßn:
    run_convert(TEST_TOPIC, TEST_KEY)
